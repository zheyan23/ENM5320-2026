{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de0fe7c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/natrask/ENM5320-2026/blob/main/NewMaterial/Lecture01_Jan15/pytorch_review.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bdd51d",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456bb1c",
   "metadata": {},
   "source": [
    "In this course we will be developing numerical solvers of differential equations in PyTorch so that we can gain access to Torch's automatic differentiation engine and integrate advanced architectures like transformers into standard scientific computing tasks. To ensure that you have sufficient background to keep up with assignments, I've put together this Jupyter notebook which summarizes PyTorch basics that you will need to be comfortable in order to keep up with the class.\n",
    "\n",
    "During lecture today, skim this notebook and give an honest self-assessment, and talk to Prof. Trask after class if you feel like this is out of reach for you. With some proactive catch-up it will be possible, but **please do not assume that you can vibe code your way out of this**. When we start developing PDE solvers in Torch we will be doing something very unusual that was not in GPT's training data and you will need to have control of the fine-grained code machinations to get something that works and complete course assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d2627",
   "metadata": {},
   "source": [
    "### Notebook outline\n",
    "\n",
    "I have structured this notebook into two pieces:\n",
    "- **Piece 1:** Basic PyTorch. You should feel comfortable at this level with PyTorch if you're going to be able to keep up. This is basic backprop, forward/backward pass, and training.\n",
    "- **Piece 2:** Advanced topics. This is the material that we will learn in the class so you can get a feel for what you will learn. We will teach this by doing - throughout the semester we will have some coding labs where we will write code together. Don't stress if this looks complicated.\n",
    "\n",
    "The point of this notebook is not for you to go through and run everything/memorize syntax. It is to help you assess the level of Python programming you will need to complete the course.\n",
    "\n",
    "**WARNING:** In my experience right now, many graduate students are completely reliant on LLMs to write code. With the current capabilities of LLMs, you can do that for Piece 1, **but not Piece 2**. This is because hundreds of thousands of people are training MLPs and transformers, but probably <20 in the world are integrating them into FEM and so an LLM will not just regurgitate the right answer. I am drawing your attention to this now so that you can budget the appropriate amount of time for this course to do some moderately serious code development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d5167",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26215f84",
   "metadata": {},
   "source": [
    "We will mostly just use vanilla pytorch, but the `einops` package will be useful to manipulate matrices and tensors. If you're running this in Colab, uncomment the following to pip install the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ca337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab)\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32790189",
   "metadata": {},
   "source": [
    "# **Piece 1.** PyTorch Review\n",
    "\n",
    "This notebook provides a comprehensive review of PyTorch fundamentals for ENM5320. We'll cover:\n",
    "- Tensor creation and operations\n",
    "- Automatic differentiation\n",
    "- Building neural networks\n",
    "- Training loops\n",
    "- GPU operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb141cc",
   "metadata": {},
   "source": [
    "### 1. Import PyTorch and Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3839fb",
   "metadata": {},
   "source": [
    "### 2. Tensor Creation and Basic Operations\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch, similar to NumPy arrays but with GPU acceleration support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors from different sources\n",
    "a = torch.zeros(3, 4)\n",
    "print(\"Zeros tensor:\\n\", a)\n",
    "\n",
    "b = torch.ones(2, 3)\n",
    "print(\"\\nOnes tensor:\\n\", b)\n",
    "\n",
    "c = torch.rand(2, 3)  # Uniform distribution [0, 1)\n",
    "print(\"\\nRandom tensor (uniform):\\n\", c)\n",
    "\n",
    "d = torch.randn(2, 3)  # Standard normal distribution\n",
    "print(\"\\nRandom tensor (normal):\\n\", d)\n",
    "\n",
    "# From Python list\n",
    "e = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"\\nTensor from list:\\n\", e)\n",
    "\n",
    "# From NumPy array\n",
    "f_np = np.array([[7, 8], [9, 10]])\n",
    "f = torch.from_numpy(f_np)\n",
    "print(\"\\nTensor from NumPy:\\n\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab751ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "y = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "# Element-wise operations\n",
    "print(\"Addition:\", x + y)\n",
    "print(\"\\nSubtraction:\", x - y)\n",
    "print(\"\\nElement-wise multiplication:\", x * y)\n",
    "print(\"\\nElement-wise division:\", x / y)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(\"\\nMatrix multiplication (x @ y.T):\\n\", x @ y.T)\n",
    "print(\"\\nMatrix multiplication (torch.mm):\\n\", torch.mm(x, y.T))\n",
    "\n",
    "# Other useful operations\n",
    "print(\"\\nMean:\", x.mean())\n",
    "print(\"Sum:\", x.sum())\n",
    "print(\"Max:\", x.max())\n",
    "print(\"Min:\", x.min())\n",
    "print(\"Standard deviation:\", x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997bc49",
   "metadata": {},
   "source": [
    "### 3. Tensor Indexing and Slicing\n",
    "\n",
    "Access and modify tensor elements using NumPy-like indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ff05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor for indexing examples\n",
    "tensor = torch.arange(0, 24).reshape(4, 6)\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "\n",
    "# Access single element\n",
    "print(\"\\nElement at [1, 2]:\", tensor[1, 2].item())\n",
    "\n",
    "# Slice rows\n",
    "print(\"\\nFirst two rows:\\n\", tensor[:2, :])\n",
    "\n",
    "# Slice columns\n",
    "print(\"\\nFirst three columns:\\n\", tensor[:, :3])\n",
    "\n",
    "# Advanced indexing\n",
    "print(\"\\nRows 1 and 3:\\n\", tensor[[1, 3], :])\n",
    "\n",
    "# Boolean indexing\n",
    "mask = tensor > 10\n",
    "print(\"\\nElements > 10:\\n\", tensor[mask])\n",
    "\n",
    "# Modify elements\n",
    "tensor[0, 0] = 100\n",
    "print(\"\\nAfter modification:\\n\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d063f3c",
   "metadata": {},
   "source": [
    "### 4. Tensor Reshaping and Broadcasting\n",
    "\n",
    "Reshape tensors and understand broadcasting rules for operations on different-sized tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping tensors\n",
    "x = torch.arange(12)\n",
    "print(\"Original shape:\", x.shape)\n",
    "print(x)\n",
    "\n",
    "# Using view (requires contiguous memory)\n",
    "x_view = x.view(3, 4)\n",
    "print(\"\\nReshaped with view (3, 4):\\n\", x_view)\n",
    "\n",
    "# Using reshape (more flexible)\n",
    "x_reshaped = x.reshape(2, 6)\n",
    "print(\"\\nReshaped with reshape (2, 6):\\n\", x_reshaped)\n",
    "\n",
    "# Transpose\n",
    "x_t = x_view.T\n",
    "print(\"\\nTransposed:\\n\", x_t)\n",
    "\n",
    "# Flatten\n",
    "x_flat = x_view.flatten()\n",
    "print(\"\\nFlattened:\", x_flat)\n",
    "\n",
    "# Squeeze and unsqueeze\n",
    "x_squeezed = torch.ones(1, 3, 1, 4)\n",
    "print(\"\\nOriginal shape:\", x_squeezed.shape)\n",
    "print(\"After squeeze:\", x_squeezed.squeeze().shape)\n",
    "\n",
    "x_unsqueezed = torch.ones(3, 4)\n",
    "print(\"\\nOriginal shape:\", x_unsqueezed.shape)\n",
    "print(\"After unsqueeze(0):\", x_unsqueezed.unsqueeze(0).shape)\n",
    "print(\"After unsqueeze(1):\", x_unsqueezed.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting examples\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
    "b = torch.tensor([10, 20, 30])            # Shape: (3,)\n",
    "\n",
    "# Broadcasting: b is automatically expanded to (2, 3)\n",
    "c = a + b\n",
    "print(\"Broadcasting addition:\\n\", c)\n",
    "\n",
    "# Broadcasting with different dimensions\n",
    "x = torch.ones(3, 4)      # Shape: (3, 4)\n",
    "y = torch.ones(4)         # Shape: (4,)\n",
    "z = x + y                 # y is broadcasted to (3, 4)\n",
    "print(\"\\nBroadcasting (3,4) + (4,):\\n\", z)\n",
    "\n",
    "# Broadcasting with explicit unsqueeze\n",
    "m = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "n = torch.tensor([10, 20, 30, 40])  # Shape: (4,)\n",
    "result = m + n  # Broadcasted to (3, 4)\n",
    "print(\"\\nBroadcasting (3,1) + (4,) to (3,4):\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cd3fc",
   "metadata": {},
   "source": [
    "### 5. Automatic Differentiation with Autograd\n",
    "\n",
    "PyTorch's autograd package provides automatic differentiation for all operations on tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56620ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic autograd example\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "z = x**2 + 2*y**3\n",
    "print(f\"z = {z.item()}\")\n",
    "\n",
    "# Backward pass - compute gradients\n",
    "z.backward()\n",
    "\n",
    "print(f\"dz/dx = {x.grad.item()}\")  # Should be 2*x = 4\n",
    "print(f\"dz/dy = {y.grad.item()}\")  # Should be 6*y^2 = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a473440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex example with vectors\n",
    "x = torch.randn(5, requires_grad=True)\n",
    "print(\"x:\", x)\n",
    "\n",
    "# Compute a scalar output\n",
    "y = (x**2).sum()\n",
    "print(\"y:\", y.item())\n",
    "\n",
    "# Compute gradients\n",
    "y.backward()\n",
    "print(\"Gradient (dy/dx):\", x.grad)\n",
    "print(\"Expected (2*x):\", 2*x.data)\n",
    "\n",
    "# Zero gradients for next computation\n",
    "x.grad.zero_()\n",
    "print(\"\\nAfter zeroing gradients:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8153b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient control: detach and no_grad\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Detach creates a new tensor that shares storage but doesn't track gradients\n",
    "y = x**2\n",
    "z = y.detach()\n",
    "print(f\"y requires_grad: {y.requires_grad}\")\n",
    "print(f\"z requires_grad: {z.requires_grad}\")\n",
    "\n",
    "# Context manager to disable gradient tracking\n",
    "with torch.no_grad():\n",
    "    w = x**3\n",
    "    print(f\"w requires_grad: {w.requires_grad}\")\n",
    "\n",
    "# This is useful during inference to save memory\n",
    "print(\"\\nUseful for inference where we don't need gradients!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338e1e6",
   "metadata": {},
   "source": [
    "### 6. Building a Simple Neural Network\n",
    "\n",
    "Use `nn.Module` to define neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = SimpleNN(input_size=10, hidden_size=20, output_size=2)\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e697136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "batch_size = 5\n",
    "input_data = torch.randn(batch_size, 10)\n",
    "output = model(input_data)\n",
    "print(f\"Input shape: {input_data.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: using nn.Sequential for simple architectures\n",
    "model_sequential = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 2)\n",
    ")\n",
    "print(model_sequential)\n",
    "\n",
    "# Test\n",
    "output_seq = model_sequential(input_data)\n",
    "print(f\"\\nSequential output shape: {output_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bf182",
   "metadata": {},
   "source": [
    "### 7. Loss Functions and Optimization\n",
    "\n",
    "PyTorch provides various loss functions and optimizers for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss functions\n",
    "# 1. Mean Squared Error (MSE) - for regression\n",
    "predictions = torch.tensor([1.5, 2.3, 3.1])\n",
    "targets = torch.tensor([1.0, 2.0, 3.0])\n",
    "mse_loss = nn.MSELoss()\n",
    "loss = mse_loss(predictions, targets)\n",
    "print(f\"MSE Loss: {loss.item()}\")\n",
    "\n",
    "# 2. Cross Entropy Loss - for classification\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "# Predictions: logits for 3 classes, batch size 2\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1], [0.5, 2.5, 0.2]])\n",
    "# Targets: class indices\n",
    "class_targets = torch.tensor([0, 1])\n",
    "loss = ce_loss(logits, class_targets)\n",
    "print(f\"Cross Entropy Loss: {loss.item()}\")\n",
    "\n",
    "# 3. Binary Cross Entropy - for binary classification\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "binary_logits = torch.tensor([0.5, -1.0, 2.0])\n",
    "binary_targets = torch.tensor([1.0, 0.0, 1.0])\n",
    "loss = bce_loss(binary_logits, binary_targets)\n",
    "print(f\"Binary Cross Entropy Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "model = SimpleNN(10, 20, 2)\n",
    "\n",
    "# 1. Stochastic Gradient Descent (SGD)\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "print(\"SGD optimizer:\", optimizer_sgd)\n",
    "\n",
    "# 2. Adam - adaptive learning rate\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"\\nAdam optimizer:\", optimizer_adam)\n",
    "\n",
    "# 3. RMSprop\n",
    "optimizer_rmsprop = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "print(\"\\nRMSprop optimizer:\", optimizer_rmsprop)\n",
    "\n",
    "# Access parameter groups\n",
    "print(\"\\nOptimizer state dict keys:\", optimizer_adam.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ea3c1",
   "metadata": {},
   "source": [
    "### 8. Training Loop Example\n",
    "\n",
    "A complete example showing the typical training loop structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01769c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data for training\n",
    "torch.manual_seed(42)\n",
    "X_train = torch.randn(100, 10)\n",
    "y_train = torch.randint(0, 2, (100,))\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SimpleNN(input_size=10, hidden_size=20, output_size=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update parameters\n",
    "    \n",
    "    # Store loss\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on training data (normally you'd use a separate test set)\n",
    "model.eval()  # Set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_train).sum().item() / len(y_train)\n",
    "    print(f'\\nTraining Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb8f13",
   "metadata": {},
   "source": [
    "### 9. GPU Operations\n",
    "\n",
    "Move tensors and models to GPU for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Memory cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91048fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors to GPU\n",
    "x_cpu = torch.randn(3, 4)\n",
    "print(f\"Tensor on CPU: {x_cpu.device}\")\n",
    "\n",
    "# Method 1: Using .to()\n",
    "x_gpu = x_cpu.to(device)\n",
    "print(f\"Tensor moved to: {x_gpu.device}\")\n",
    "\n",
    "# Method 2: Using .cuda() (if available)\n",
    "if torch.cuda.is_available():\n",
    "    x_cuda = x_cpu.cuda()\n",
    "    print(f\"Tensor on GPU: {x_cuda.device}\")\n",
    "    \n",
    "    # Move back to CPU\n",
    "    x_back = x_cuda.cpu()\n",
    "    print(f\"Tensor back on CPU: {x_back.device}\")\n",
    "\n",
    "# Create tensor directly on device\n",
    "y = torch.randn(3, 4, device=device)\n",
    "print(f\"Tensor created on: {y.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU\n",
    "model = SimpleNN(10, 20, 2)\n",
    "model = model.to(device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Training with GPU\n",
    "X_train_gpu = torch.randn(100, 10, device=device)\n",
    "y_train_gpu = torch.randint(0, 2, (100,), device=device)\n",
    "\n",
    "# Verify all on same device\n",
    "print(f\"Input device: {X_train_gpu.device}\")\n",
    "print(f\"Target device: {y_train_gpu.device}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Forward pass on GPU\n",
    "outputs = model(X_train_gpu)\n",
    "print(f\"Output device: {outputs.device}\")\n",
    "print(f\"Output shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89ddee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered the essential PyTorch concepts:\n",
    "- **Tensor operations**: Creation, indexing, slicing, reshaping, and broadcasting\n",
    "- **Autograd**: Automatic differentiation for gradient computation\n",
    "- **Neural networks**: Building models with `nn.Module` and `nn.Sequential`\n",
    "- **Training**: Loss functions, optimizers, and the training loop\n",
    "- **GPU acceleration**: Moving tensors and models to GPU for faster computation\n",
    "\n",
    "For more information, visit the [PyTorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689ef22",
   "metadata": {},
   "source": [
    "# **Piece 2.** Advanced topics for scientific computing in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9d35f",
   "metadata": {},
   "source": [
    "## Using einops for Tensor Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b582767",
   "metadata": {},
   "source": [
    "The `einops` library provides a cleaner, more readable way to perform tensor operations like rearranging, reducing, and repeating. It uses Einstein notation-inspired syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, reduce, repeat\n",
    "import torch\n",
    "\n",
    "# Create a sample tensor: batch of images\n",
    "# Shape: (batch, channels, height, width)\n",
    "images = torch.randn(4, 3, 28, 28)\n",
    "print(f\"Original shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd626bd",
   "metadata": {},
   "source": [
    "### 1. Rearrange - Reshaping and Transposing\n",
    "\n",
    "The `rearrange` function is perfect for reshaping, transposing, and reordering dimensions with readable syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Transpose dimensions\n",
    "# Swap batch and channel dimensions\n",
    "transposed = rearrange(images, 'b c h w -> c b h w')\n",
    "print(f\"After transpose: {transposed.shape}\")\n",
    "\n",
    "# Example 2: Flatten spatial dimensions\n",
    "# Convert (batch, channel, height, width) to (batch, channel, pixels)\n",
    "flattened = rearrange(images, 'b c h w -> b c (h w)')\n",
    "print(f\"Flattened spatial: {flattened.shape}\")\n",
    "\n",
    "# Example 3: Flatten completely\n",
    "# Convert to (batch, features)\n",
    "flat = rearrange(images, 'b c h w -> b (c h w)')\n",
    "print(f\"Completely flat: {flat.shape}\")\n",
    "\n",
    "# Example 4: Split dimensions\n",
    "# Split height and width into patches\n",
    "patches = rearrange(images, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=7, p2=7)\n",
    "print(f\"Image patches (7x7): {patches.shape}\")  # 4 batches, 16 patches, 147 features per patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecfbb2",
   "metadata": {},
   "source": [
    "### 2. Reduce - Aggregation Operations\n",
    "\n",
    "The `reduce` function performs reductions (mean, max, min, sum) along specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Global average pooling\n",
    "# Average over spatial dimensions\n",
    "pooled = reduce(images, 'b c h w -> b c', 'mean')\n",
    "print(f\"Global average pooled: {pooled.shape}\")\n",
    "\n",
    "# Example 2: Average over channels\n",
    "channel_avg = reduce(images, 'b c h w -> b h w', 'mean')\n",
    "print(f\"Channel-averaged: {channel_avg.shape}\")\n",
    "\n",
    "# Example 3: Max pooling over spatial dimensions\n",
    "max_pooled = reduce(images, 'b c h w -> b c', 'max')\n",
    "print(f\"Max pooled: {max_pooled.shape}\")\n",
    "\n",
    "# Example 4: Sum with spatial reduction\n",
    "summed = reduce(images, 'b c h w -> b c', 'sum')\n",
    "print(f\"Spatial sum: {summed.shape}\")\n",
    "\n",
    "# Example 5: Combining with rearrangement - patch-wise mean\n",
    "patch_mean = reduce(images, 'b c (h p1) (w p2) -> b c h w', 'mean', p1=7, p2=7)\n",
    "print(f\"Patch-wise mean: {patch_mean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655dd03",
   "metadata": {},
   "source": [
    "### 3. Repeat - Replicating Tensors\n",
    "\n",
    "The `repeat` function duplicates data along specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller tensor for demonstration\n",
    "vector = torch.randn(3)\n",
    "print(f\"Original vector: {vector.shape}\")\n",
    "\n",
    "# Example 1: Repeat along new dimension\n",
    "repeated = repeat(vector, 'c -> b c', b=4)\n",
    "print(f\"Repeated along batch: {repeated.shape}\")\n",
    "print(repeated)\n",
    "\n",
    "# Example 2: Create a matrix from vector\n",
    "matrix = repeat(vector, 'c -> c h', h=5)\n",
    "print(f\"\\nRepeated to matrix: {matrix.shape}\")\n",
    "\n",
    "# Example 3: Tile a small image\n",
    "small_image = torch.randn(1, 3, 8, 8)\n",
    "tiled = repeat(small_image, 'b c h w -> b c (h tile1) (w tile2)', tile1=3, tile2=3)\n",
    "print(f\"\\nTiled image: {tiled.shape}\")\n",
    "\n",
    "# Example 4: Broadcasting-like operation\n",
    "# Repeat a bias vector for each batch element and spatial location\n",
    "bias = torch.randn(3)\n",
    "broadcasted = repeat(bias, 'c -> b c h w', b=4, h=28, w=28)\n",
    "print(f\"Broadcasted bias: {broadcasted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1fb7f",
   "metadata": {},
   "source": [
    "### 4. Practical Examples\n",
    "\n",
    "Combining einops operations for common deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Vision Transformer (ViT) - Image to patches\n",
    "image = torch.randn(1, 3, 224, 224)\n",
    "patch_size = 16\n",
    "patches = rearrange(image, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size)\n",
    "print(f\"ViT patches: {patches.shape}\")  # (1, 196, 768) - 196 patches of 768 dims\n",
    "\n",
    "# Example 2: Batch matrix multiplication with einops\n",
    "batch_size, seq_len, dim = 4, 10, 64\n",
    "queries = torch.randn(batch_size, seq_len, dim)\n",
    "keys = torch.randn(batch_size, seq_len, dim)\n",
    "\n",
    "# Attention scores: rearrange for batch matrix multiplication\n",
    "q_rearranged = rearrange(queries, 'b n d -> b n d')\n",
    "k_rearranged = rearrange(keys, 'b n d -> b d n')\n",
    "attention_scores = torch.bmm(q_rearranged, k_rearranged)\n",
    "print(f\"Attention scores: {attention_scores.shape}\")\n",
    "\n",
    "# Example 3: Converting between different data formats\n",
    "# NCHW (PyTorch) to NHWC (TensorFlow)\n",
    "nchw_tensor = torch.randn(8, 3, 32, 32)\n",
    "nhwc_tensor = rearrange(nchw_tensor, 'b c h w -> b h w c')\n",
    "print(f\"NCHW to NHWC: {nchw_tensor.shape} -> {nhwc_tensor.shape}\")\n",
    "\n",
    "# Example 4: Spatial Average Pooling (alternative to nn.AdaptiveAvgPool2d)\n",
    "feature_map = torch.randn(4, 256, 7, 7)\n",
    "pooled_features = reduce(feature_map, 'b c h w -> b c', 'mean')\n",
    "print(f\"Spatial pooling: {feature_map.shape} -> {pooled_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b011f8",
   "metadata": {},
   "source": [
    "### 5. Why Use einops?\n",
    "\n",
    "**Advantages:**\n",
    "- **Readability**: Operations are self-documenting with named dimensions\n",
    "- **Fewer bugs**: Explicit dimension names reduce indexing errors\n",
    "- **Composability**: Complex operations become simple one-liners\n",
    "- **Framework agnostic**: Works with PyTorch, TensorFlow, JAX, and NumPy\n",
    "\n",
    "**Comparison:**\n",
    "```python\n",
    "# Traditional PyTorch\n",
    "x = x.permute(0, 2, 3, 1).reshape(batch, -1, channels)\n",
    "\n",
    "# With einops\n",
    "x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "```\n",
    "\n",
    "The einops version clearly shows what transformation is being performed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353a3c2",
   "metadata": {},
   "source": [
    "### 6. Tensor Contraction with einops vs einsum\n",
    "\n",
    "Tensor contraction is a generalization of matrix multiplication. While `torch.einsum` is convenient, it can be slow, especially for sparse tensors. Using `einops` with optimized matrix multiplications is often faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Setup: Create sample tensors for benchmarking\n",
    "batch_size, seq_len, dim = 32, 128, 512\n",
    "A = torch.randn(batch_size, seq_len, dim)\n",
    "B = torch.randn(batch_size, dim, seq_len)\n",
    "\n",
    "print(f\"Tensor shapes: A={A.shape}, B={B.shape}\")\n",
    "print(f\"Goal: Batch matrix multiplication -> ({batch_size}, {seq_len}, {seq_len})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1403b",
   "metadata": {},
   "source": [
    "#### Method 1: Using torch.einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using einsum notation\n",
    "# 'bik,bkj->bij' means: batch, i, k @ batch, k, j -> batch, i, j\n",
    "\n",
    "# Warmup\n",
    "for _ in range(10):\n",
    "    _ = torch.einsum('bik,bkj->bij', A, B)\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    result_einsum = torch.einsum('bik,bkj->bij', A, B)\n",
    "einsum_time = (time.time() - start) / 100\n",
    "\n",
    "print(f\"Result shape: {result_einsum.shape}\")\n",
    "print(f\"Average time (einsum): {einsum_time*1000:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104decec",
   "metadata": {},
   "source": [
    "#### Method 2: Using torch.bmm (Batch Matrix Multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using optimized batch matrix multiplication\n",
    "# torch.bmm is highly optimized and calls BLAS/cuBLAS directly\n",
    "\n",
    "# Warmup\n",
    "for _ in range(10):\n",
    "    _ = torch.bmm(A, B)\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    result_bmm = torch.bmm(A, B)\n",
    "bmm_time = (time.time() - start) / 100\n",
    "\n",
    "print(f\"Result shape: {result_bmm.shape}\")\n",
    "print(f\"Average time (bmm): {bmm_time*1000:.3f} ms\")\n",
    "print(f\"Speedup: {einsum_time/bmm_time:.2f}x faster\")\n",
    "\n",
    "# Verify results are the same\n",
    "print(f\"\\nResults match: {torch.allclose(result_einsum, result_bmm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6514b38",
   "metadata": {},
   "source": [
    "#### Method 3: Using einops + matmul (@ operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using einops for readability with @ operator for speed\n",
    "# The @ operator calls the same optimized backends as torch.bmm\n",
    "\n",
    "# Warmup\n",
    "for _ in range(10):\n",
    "    _ = A @ B\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    result_matmul = A @ B\n",
    "matmul_time = (time.time() - start) / 100\n",
    "\n",
    "print(f\"Result shape: {result_matmul.shape}\")\n",
    "print(f\"Average time (@): {matmul_time*1000:.3f} ms\")\n",
    "print(f\"Speedup vs einsum: {einsum_time/matmul_time:.2f}x faster\")\n",
    "\n",
    "# For more complex operations, einops makes it readable\n",
    "# Example: tensor contraction with rearrangement\n",
    "C = torch.randn(batch_size, dim, seq_len, 64)\n",
    "# Contract over dim, resulting in (batch, seq_len, seq_len, 64)\n",
    "result_complex = rearrange(A, 'b i d -> b i d 1') @ rearrange(C, 'b d j k -> b 1 d (j k)')\n",
    "result_complex = rearrange(result_complex, 'b i 1 jk -> b i jk')\n",
    "print(f\"\\nComplex contraction result: {result_complex.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6564eb",
   "metadata": {},
   "source": [
    "#### Why is einsum slower?\n",
    "\n",
    "**Key reasons:**\n",
    "\n",
    "1. **Generic implementation**: `einsum` handles arbitrary tensor contractions, so it can't always optimize for specific patterns like matrix multiplication\n",
    "\n",
    "2. **Memory layout**: `einsum` may need to transpose/reshape tensors internally, creating temporary copies\n",
    "\n",
    "3. **BLAS optimization**: `torch.bmm` and `@` directly call highly optimized BLAS (CPU) or cuBLAS (GPU) libraries that use:\n",
    "   - Cache-optimized memory access patterns\n",
    "   - SIMD vectorization\n",
    "   - Specialized hardware instructions (e.g., tensor cores on NVIDIA GPUs)\n",
    "\n",
    "4. **Sparse tensors**: `einsum` is **particularly slow** for sparse tensors because:\n",
    "   - It often materializes dense intermediate results\n",
    "   - Doesn't leverage sparse-specific algorithms (CSR/CSC matrix multiplication)\n",
    "   - Can't skip zero elements efficiently\n",
    "\n",
    "**Recommendation:**\n",
    "- Use `einsum` for quick prototyping and unusual contractions\n",
    "- For production code, rearrange with `einops` then use `@`, `torch.bmm`, or `torch.matmul`\n",
    "- For sparse tensors, **always** use `torch.sparse.mm` or `@` instead of `einsum`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f19450",
   "metadata": {},
   "source": [
    "#### Sparse Tensor Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse matrix (e.g., adjacency matrix for a graph)\n",
    "size = 1000\n",
    "sparsity = 0.01  # 1% non-zero elements\n",
    "\n",
    "# Create sparse tensor in COO format\n",
    "indices = torch.randint(0, size, (2, int(size * size * sparsity)))\n",
    "values = torch.randn(int(size * size * sparsity))\n",
    "sparse_matrix = torch.sparse_coo_tensor(indices, values, (size, size))\n",
    "\n",
    "# Dense vector\n",
    "dense_vec = torch.randn(size, 100)\n",
    "\n",
    "print(f\"Sparse matrix: {size}x{size} with {sparsity*100}% non-zero\")\n",
    "print(f\"Dense vector: {dense_vec.shape}\")\n",
    "\n",
    "# Method 1: Using sparse @ (FAST - uses sparse algorithms)\n",
    "start = time.time()\n",
    "result_sparse = sparse_matrix @ dense_vec\n",
    "sparse_time = time.time() - start\n",
    "print(f\"\\nSparse @ time: {sparse_time*1000:.3f} ms\")\n",
    "\n",
    "# Method 2: If we convert to dense and use einsum (SLOW - wastes memory)\n",
    "dense_matrix = sparse_matrix.to_dense()\n",
    "start = time.time()\n",
    "result_dense = torch.einsum('ij,jk->ik', dense_matrix, dense_vec)\n",
    "dense_time = time.time() - start\n",
    "print(f\"Dense einsum time: {dense_time*1000:.3f} ms\")\n",
    "print(f\"Speedup: {dense_time/sparse_time:.2f}x faster with sparse operations\")\n",
    "\n",
    "# Memory comparison\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(f\"Sparse: ~{sparse_matrix._values().nelement() * 4 / 1e6:.2f} MB\")\n",
    "print(f\"Dense: ~{size * size * 4 / 1e6:.2f} MB\")\n",
    "print(f\"Ratio: {(size * size) / sparse_matrix._values().nelement():.1f}x more memory for dense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d17cc2",
   "metadata": {},
   "source": [
    "#### Best Practices Summary\n",
    "\n",
    "**For dense tensors:**\n",
    "1. Use `einops.rearrange` to make dimensions clear\n",
    "2. Use `@`, `torch.bmm`, or `torch.matmul` for actual computation\n",
    "3. Avoid `einsum` in performance-critical code\n",
    "\n",
    "**For sparse tensors:**\n",
    "1. **Never** use `einsum` - it will materialize dense intermediates\n",
    "2. Use `@` operator or `torch.sparse.mm` \n",
    "3. Keep computations in sparse format as long as possible\n",
    "4. Only convert to dense if absolutely necessary\n",
    "\n",
    "**Example pattern:**\n",
    "```python\n",
    "# Good: readable + fast\n",
    "x = rearrange(x, 'b h w c -> b (h w) c')\n",
    "result = x @ weight  # Uses optimized BLAS\n",
    "\n",
    "# Bad: slow, especially for large tensors\n",
    "result = torch.einsum('bhwc,cd->bhwd', x, weight)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a895a54",
   "metadata": {},
   "source": [
    "### 7. Backpropagation Through Sparse Linear Solves\n",
    "\n",
    "When solving linear systems $Ax = b$ in neural networks or PDE solvers, we often need gradients. PyTorch doesn't natively support autograd through `torch.linalg.solve` for sparse matrices, so we need custom implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57eb605",
   "metadata": {},
   "source": [
    "#### The Math: Implicit Function Theorem\n",
    "\n",
    "For $Ax = b$, we want $\\frac{\\partial x}{\\partial \\theta}$ where $\\theta$ are parameters in $A$ or $b$.\n",
    "\n",
    "Using the implicit function theorem:\n",
    "- Forward: Solve $Ax = b$ for $x$\n",
    "- Backward: Given $\\bar{x}$ (gradient from upstream), compute:\n",
    "  - $\\frac{\\partial L}{\\partial b} = A^{-T} \\bar{x}$ (solve $A^T \\lambda = \\bar{x}$)\n",
    "  - $\\frac{\\partial L}{\\partial A} = -\\lambda x^T$ where $\\lambda$ is from above\n",
    "\n",
    "**Key insight**: We never form $A^{-1}$ explicitly. We solve two linear systems (forward and backward)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0825e10",
   "metadata": {},
   "source": [
    "#### Implementation: Custom Autograd Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b9d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseSolve(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd function for solving Ax = b with sparse A.\n",
    "    Implements efficient backward pass using implicit differentiation.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, A, b):\n",
    "        \"\"\"\n",
    "        Solve Ax = b for x.\n",
    "        \n",
    "        Args:\n",
    "            A: Sparse matrix (n x n)\n",
    "            b: Right-hand side (n,) or (n, k)\n",
    "        \n",
    "        Returns:\n",
    "            x: Solution to Ax = b\n",
    "        \"\"\"\n",
    "        # For sparse matrices, we typically use iterative solvers\n",
    "        # or convert to dense for small problems\n",
    "        \n",
    "        # Option 1: Dense solve (for moderate-sized systems)\n",
    "        if A.is_sparse:\n",
    "            A_dense = A.to_dense()\n",
    "        else:\n",
    "            A_dense = A\n",
    "            \n",
    "        x = torch.linalg.solve(A_dense, b)\n",
    "        \n",
    "        # Save for backward pass\n",
    "        ctx.save_for_backward(A_dense, x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_x):\n",
    "        \"\"\"\n",
    "        Compute gradients using implicit differentiation.\n",
    "        \n",
    "        Given grad_x (∂L/∂x), compute:\n",
    "        - grad_A: ∂L/∂A\n",
    "        - grad_b: ∂L/∂b\n",
    "        \"\"\"\n",
    "        A, x = ctx.saved_tensors\n",
    "        \n",
    "        # Solve A^T λ = grad_x for λ\n",
    "        # This is the adjoint equation\n",
    "        lambda_ = torch.linalg.solve(A.T, grad_x)\n",
    "        \n",
    "        # Gradient w.r.t. b: ∂L/∂b = λ\n",
    "        grad_b = lambda_\n",
    "        \n",
    "        # Gradient w.r.t. A: ∂L/∂A = -λ x^T\n",
    "        if x.dim() == 1:\n",
    "            grad_A = -torch.outer(lambda_, x)\n",
    "        else:\n",
    "            grad_A = -torch.mm(lambda_, x.T)\n",
    "        \n",
    "        return grad_A, grad_b\n",
    "\n",
    "# Create a wrapper function for convenience\n",
    "def sparse_solve(A, b):\n",
    "    \"\"\"Solve Ax = b with autograd support.\"\"\"\n",
    "    return SparseSolve.apply(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57329126",
   "metadata": {},
   "source": [
    "#### Example: Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test case\n",
    "n = 5\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a symmetric positive definite matrix (ensures unique solution)\n",
    "A_base = torch.randn(n, n, requires_grad=True)\n",
    "A = A_base @ A_base.T + torch.eye(n)  # SPD matrix\n",
    "\n",
    "# Right-hand side\n",
    "b = torch.randn(n, requires_grad=True)\n",
    "\n",
    "# Solve using our custom function\n",
    "x = sparse_solve(A, b)\n",
    "print(f\"Solution x: {x}\")\n",
    "\n",
    "# Create a scalar loss (e.g., L2 norm of solution)\n",
    "loss = (x ** 2).sum()\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "print(f\"\\nGradients computed:\")\n",
    "print(f\"grad_A shape: {A.grad.shape}\")\n",
    "print(f\"grad_b shape: {b.grad.shape}\")\n",
    "print(f\"\\ngrad_b: {b.grad}\")\n",
    "\n",
    "# Verify with numerical gradients (finite differences)\n",
    "print(\"\\n--- Gradient Check ---\")\n",
    "eps = 1e-5\n",
    "\n",
    "# Check gradient w.r.t. b\n",
    "b_test = b.detach().clone().requires_grad_(True)\n",
    "A_test = A.detach()\n",
    "x_test = sparse_solve(A_test, b_test)\n",
    "loss_test = (x_test ** 2).sum()\n",
    "loss_test.backward()\n",
    "\n",
    "# Numerical gradient for b[0]\n",
    "b_plus = b.detach().clone()\n",
    "b_plus[0] += eps\n",
    "x_plus = sparse_solve(A_test, b_plus)\n",
    "loss_plus = (x_plus ** 2).sum()\n",
    "\n",
    "b_minus = b.detach().clone()\n",
    "b_minus[0] -= eps\n",
    "x_minus = sparse_solve(A_test, b_minus)\n",
    "loss_minus = (x_minus ** 2).sum()\n",
    "\n",
    "numerical_grad_b0 = (loss_plus - loss_minus) / (2 * eps)\n",
    "analytical_grad_b0 = b_test.grad[0]\n",
    "\n",
    "print(f\"Numerical grad_b[0]: {numerical_grad_b0.item():.6f}\")\n",
    "print(f\"Analytical grad_b[0]: {analytical_grad_b0.item():.6f}\")\n",
    "print(f\"Relative error: {abs(numerical_grad_b0 - analytical_grad_b0) / abs(numerical_grad_b0):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929d39e",
   "metadata": {},
   "source": [
    "#### Optimization: Using Iterative Solvers\n",
    "\n",
    "For large sparse systems, we should use iterative solvers (CG, GMRES, BiCGSTAB) instead of direct solvers. Here's an example with Conjugate Gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a03aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(A, b, x0=None, tol=1e-5, max_iter=100):\n",
    "    \"\"\"\n",
    "    Solve Ax = b using Conjugate Gradient (for SPD matrices).\n",
    "    \n",
    "    Args:\n",
    "        A: Sparse or dense SPD matrix\n",
    "        b: Right-hand side\n",
    "        x0: Initial guess (if None, use zeros)\n",
    "        tol: Convergence tolerance\n",
    "        max_iter: Maximum iterations\n",
    "    \n",
    "    Returns:\n",
    "        x: Solution\n",
    "    \"\"\"\n",
    "    n = b.shape[0]\n",
    "    if x0 is None:\n",
    "        x = torch.zeros_like(b)\n",
    "    else:\n",
    "        x = x0.clone()\n",
    "    \n",
    "    # Initial residual\n",
    "    r = b - A @ x\n",
    "    p = r.clone()\n",
    "    rsold = torch.dot(r, r)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        Ap = A @ p\n",
    "        alpha = rsold / torch.dot(p, Ap)\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "        rsnew = torch.dot(r, r)\n",
    "        \n",
    "        if torch.sqrt(rsnew) < tol:\n",
    "            print(f\"CG converged in {i+1} iterations\")\n",
    "            break\n",
    "        \n",
    "        beta = rsnew / rsold\n",
    "        p = r + beta * p\n",
    "        rsold = rsnew\n",
    "    \n",
    "    return x\n",
    "\n",
    "class SparseSolveCG(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Sparse solve using Conjugate Gradient with autograd support.\n",
    "    More efficient for large sparse systems.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, A, b, tol=1e-5):\n",
    "        x = conjugate_gradient(A, b, tol=tol)\n",
    "        ctx.save_for_backward(A, x)\n",
    "        ctx.tol = tol\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_x):\n",
    "        A, x = ctx.saved_tensors\n",
    "        \n",
    "        # Solve A^T λ = grad_x using CG\n",
    "        # For SPD matrices, A^T = A, so we can reuse CG\n",
    "        lambda_ = conjugate_gradient(A.T, grad_x, tol=ctx.tol)\n",
    "        \n",
    "        grad_b = lambda_\n",
    "        grad_A = -torch.outer(lambda_, x)\n",
    "        \n",
    "        return grad_A, grad_b, None\n",
    "\n",
    "# Wrapper function\n",
    "def sparse_solve_cg(A, b, tol=1e-5):\n",
    "    return SparseSolveCG.apply(A, b, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CG solver with larger system\n",
    "n = 50\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Create a sparse SPD matrix (e.g., from a discretized Poisson equation)\n",
    "# Create tridiagonal matrix: -1, 2, -1 pattern\n",
    "diag = 2 * torch.ones(n, requires_grad=True)\n",
    "off_diag = -torch.ones(n-1, requires_grad=True)\n",
    "A_sparse = (torch.diag(diag) + \n",
    "            torch.diag(off_diag, diagonal=1) + \n",
    "            torch.diag(off_diag, diagonal=-1))\n",
    "\n",
    "b_sparse = torch.randn(n, requires_grad=True)\n",
    "\n",
    "# Solve using CG\n",
    "print(\"Solving with Conjugate Gradient:\")\n",
    "x_cg = sparse_solve_cg(A_sparse, b_sparse, tol=1e-6)\n",
    "\n",
    "# Verify solution\n",
    "residual = torch.norm(A_sparse @ x_cg - b_sparse)\n",
    "print(f\"Residual: {residual.item():.2e}\")\n",
    "\n",
    "# Test gradients\n",
    "loss = (x_cg ** 2).sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"\\nGradients computed successfully\")\n",
    "print(f\"grad_diag shape: {diag.grad.shape}\")\n",
    "print(f\"grad_b norm: {torch.norm(b_sparse.grad).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309c075",
   "metadata": {},
   "source": [
    "#### Key Considerations for PDE Solvers\n",
    "\n",
    "**Memory efficiency:**\n",
    "- Direct solve: $O(n^2)$ memory for dense $A^{-1}$\n",
    "- Iterative solve: $O(n)$ memory, only store sparse $A$\n",
    "\n",
    "**Computational cost:**\n",
    "- Forward: One solve (direct or iterative)\n",
    "- Backward: One additional solve for adjoint equation\n",
    "\n",
    "**Stability:**\n",
    "- Ensure $A$ is well-conditioned (use preconditioning if needed)\n",
    "- For non-SPD matrices, use GMRES or BiCGSTAB instead of CG\n",
    "- Monitor convergence in both forward and backward passes\n",
    "\n",
    "**Advanced techniques:**\n",
    "1. **Checkpointing**: For very large systems, don't save $A$ and $x$ in `ctx`. Recompute them in backward pass.\n",
    "2. **Preconditioning**: Apply preconditioner $M^{-1}$ to speed up iterative solvers\n",
    "3. **Matrix-free**: Implement $A$ as a function (e.g., finite difference operator) instead of storing explicitly\n",
    "\n",
    "**Common use cases:**\n",
    "- Poisson equation solvers in physics-informed neural networks (PINNs)\n",
    "- Implicit time-stepping in neural ODEs\n",
    "- Optimization problems with PDE constraints\n",
    "- Inverse problems (parameter estimation from observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5b0f4",
   "metadata": {},
   "source": [
    "#### Example: Simple Poisson Equation\n",
    "\n",
    "Let's solve $-\\nabla^2 u = f$ on $[0,1]$ with $u(0) = u(1) = 0$ and backprop through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize Poisson equation using finite differences\n",
    "def poisson_matrix_1d(n, h):\n",
    "    \"\"\"\n",
    "    Create 1D Poisson matrix: -u'' = f\n",
    "    Discretized as: (u[i-1] - 2*u[i] + u[i+1]) / h^2 = -f[i]\n",
    "    \"\"\"\n",
    "    diag = (2.0 / h**2) * torch.ones(n)\n",
    "    off_diag = (-1.0 / h**2) * torch.ones(n-1)\n",
    "    A = torch.diag(diag) + torch.diag(off_diag, 1) + torch.diag(off_diag, -1)\n",
    "    return A\n",
    "\n",
    "# Problem setup\n",
    "n = 30  # Interior points\n",
    "L = 1.0  # Domain length\n",
    "h = L / (n + 1)  # Grid spacing\n",
    "x = torch.linspace(h, L - h, n)\n",
    "\n",
    "# Create learnable forcing function (parameterized)\n",
    "# f(x) = a * sin(pi * x) where a is learnable\n",
    "a = torch.tensor(10.0, requires_grad=True)\n",
    "f = a * torch.sin(torch.pi * x)\n",
    "\n",
    "# Create Poisson matrix\n",
    "A_poisson = poisson_matrix_1d(n, h)\n",
    "\n",
    "# Solve: -u'' = f\n",
    "print(\"Solving Poisson equation...\")\n",
    "u = sparse_solve(A_poisson, f)\n",
    "\n",
    "# Define loss: want solution close to target\n",
    "u_target = torch.sin(2 * torch.pi * x)  # Target solution\n",
    "loss_pde = ((u - u_target) ** 2).mean()\n",
    "\n",
    "print(f\"Initial loss: {loss_pde.item():.6f}\")\n",
    "print(f\"Parameter a: {a.item():.4f}\")\n",
    "\n",
    "# Optimize the parameter\n",
    "optimizer = torch.optim.Adam([a], lr=0.5)\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Re-solve with updated parameter\n",
    "    f = a * torch.sin(torch.pi * x)\n",
    "    u = sparse_solve(A_poisson, f)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss_pde = ((u - u_target) ** 2).mean()\n",
    "    \n",
    "    # Backprop through the solve!\n",
    "    loss_pde.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss_pde.item():.6f}, a = {a.item():.4f}\")\n",
    "\n",
    "print(f\"\\nFinal parameter: a = {a.item():.4f}\")\n",
    "print(f\"Final loss: {loss_pde.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89661573",
   "metadata": {},
   "source": [
    "# Advanced Differentiation: functorch\n",
    "\n",
    "PyTorch's `functorch` library (now part of `torch.func`) provides JAX-like functional transformations including `vmap` (vectorization) and `jacrev`/`jacfwd` (Jacobian computation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9185d6",
   "metadata": {},
   "source": [
    "## vmap - Vectorized Mapping\n",
    "\n",
    "`vmap` automatically vectorizes a function over batch dimensions, eliminating manual loops and enabling better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f40d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import vmap\n",
    "\n",
    "# Example function that operates on a single input\n",
    "def compute_norm(x):\n",
    "    \"\"\"Compute L2 norm of a vector.\"\"\"\n",
    "    return torch.sqrt((x ** 2).sum())\n",
    "\n",
    "# Test with a single vector\n",
    "single_vec = torch.randn(5)\n",
    "print(f\"Single vector norm: {compute_norm(single_vec).item():.4f}\")\n",
    "\n",
    "# Without vmap: manual loop over batch\n",
    "batch_vecs = torch.randn(10, 5)  # 10 vectors of dimension 5\n",
    "norms_loop = torch.stack([compute_norm(v) for v in batch_vecs])\n",
    "print(f\"\\nNorms (loop): {norms_loop[:3]}...\")\n",
    "\n",
    "# With vmap: automatic vectorization\n",
    "norms_vmap = vmap(compute_norm)(batch_vecs)\n",
    "print(f\"Norms (vmap): {norms_vmap[:3]}...\")\n",
    "\n",
    "# Verify they're the same\n",
    "print(f\"\\nResults match: {torch.allclose(norms_loop, norms_vmap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ee9cd",
   "metadata": {},
   "source": [
    "### Why use vmap?\n",
    "\n",
    "1. **Cleaner code**: Write functions for single examples, vmap handles batching\n",
    "2. **Better performance**: Can leverage vectorized operations and avoid Python loops\n",
    "3. **Composability**: Can combine with other functorch transforms (grad, jacrev, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Matrix-vector products for a batch\n",
    "def matvec(A, x):\n",
    "    \"\"\"Single matrix-vector product.\"\"\"\n",
    "    return A @ x\n",
    "\n",
    "# Batch of matrices and vectors\n",
    "batch_size = 8\n",
    "matrices = torch.randn(batch_size, 4, 4)\n",
    "vectors = torch.randn(batch_size, 4)\n",
    "\n",
    "# vmap over the batch dimension (dim 0)\n",
    "batched_matvec = vmap(matvec)\n",
    "result = batched_matvec(matrices, vectors)\n",
    "print(f\"Batched result shape: {result.shape}\")\n",
    "\n",
    "# Verify against manual batch matmul\n",
    "manual_result = torch.bmm(matrices, vectors.unsqueeze(-1)).squeeze(-1)\n",
    "print(f\"Results match: {torch.allclose(result, manual_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a6e240",
   "metadata": {},
   "source": [
    "### Advanced: Nested vmap and Custom Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested vmap for 2D batching\n",
    "def dot_product(x, y):\n",
    "    return (x * y).sum()\n",
    "\n",
    "# Create 2D batch: (batch1, batch2, features)\n",
    "x_2d = torch.randn(3, 4, 5)\n",
    "y_2d = torch.randn(3, 4, 5)\n",
    "\n",
    "# Apply vmap twice to handle both batch dimensions\n",
    "batched_dot = vmap(vmap(dot_product))\n",
    "result_2d = batched_dot(x_2d, y_2d)\n",
    "print(f\"2D batched result shape: {result_2d.shape}\")\n",
    "\n",
    "# Custom in_dims: specify which dimension to vmap over\n",
    "# Say we have data with shape (features, batch) instead of (batch, features)\n",
    "x_transposed = torch.randn(5, 10)  # features first\n",
    "y_transposed = torch.randn(5, 10)\n",
    "\n",
    "# vmap over dimension 1 (the batch dimension)\n",
    "batched_dot_custom = vmap(dot_product, in_dims=(1, 1))\n",
    "result_custom = batched_dot_custom(x_transposed, y_transposed)\n",
    "print(f\"Custom dim result shape: {result_custom.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a573f",
   "metadata": {},
   "source": [
    "## jacrev - Jacobian via Reverse Mode\n",
    "\n",
    "`jacrev` computes the Jacobian matrix using reverse-mode autodiff. Best when **outputs >> inputs** (wide Jacobian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc667956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev, jacfwd\n",
    "\n",
    "# Define a function f: R^n -> R^m\n",
    "def f(x):\n",
    "    \"\"\"Example: f(x) = [x1^2 + x2, x1 * x2, sin(x1)]\"\"\"\n",
    "    return torch.stack([\n",
    "        x[0]**2 + x[1],\n",
    "        x[0] * x[1],\n",
    "        torch.sin(x[0])\n",
    "    ])\n",
    "\n",
    "# Input point\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Output: {f(x)}\")\n",
    "\n",
    "# Compute Jacobian using reverse mode\n",
    "jacobian_rev = jacrev(f)(x)\n",
    "print(f\"\\nJacobian (jacrev):\\n{jacobian_rev}\")\n",
    "print(f\"Shape: {jacobian_rev.shape}  # (outputs, inputs)\")\n",
    "\n",
    "# Manual verification of first row: d(x1^2 + x2)/dx\n",
    "# df1/dx1 = 2*x1 = 2*1 = 2\n",
    "# df1/dx2 = 1\n",
    "print(f\"\\nExpected first row: [2.0, 1.0]\")\n",
    "print(f\"Computed first row: {jacobian_rev[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176873",
   "metadata": {},
   "source": [
    "### jacrev vs jacfwd: When to Use Which?\n",
    "\n",
    "**jacrev (reverse mode):**\n",
    "- Best when **m >> n** (many outputs, few inputs)\n",
    "- One backward pass per output\n",
    "- Complexity: O(m) backward passes\n",
    "\n",
    "**jacfwd (forward mode):**\n",
    "- Best when **n >> m** (many inputs, few outputs)\n",
    "- One forward pass per input\n",
    "- Complexity: O(n) forward passes\n",
    "\n",
    "**Rule of thumb:** Use jacrev for \"tall\" Jacobians, jacfwd for \"wide\" Jacobians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare jacrev vs jacfwd\n",
    "def g(x):\n",
    "    \"\"\"Function R^10 -> R^3 (wide Jacobian)\"\"\"\n",
    "    return torch.stack([\n",
    "        x.sum(),\n",
    "        (x**2).sum(),\n",
    "        (x**3).sum()\n",
    "    ])\n",
    "\n",
    "x_wide = torch.randn(10)\n",
    "\n",
    "# jacfwd is better here (fewer outputs)\n",
    "jac_fwd = jacfwd(g)(x_wide)\n",
    "print(f\"jacfwd result shape: {jac_fwd.shape}  # (3, 10)\")\n",
    "\n",
    "# jacrev works too, but less efficient\n",
    "jac_rev = jacrev(g)(x_wide)\n",
    "print(f\"jacrev result shape: {jac_rev.shape}  # (3, 10)\")\n",
    "\n",
    "print(f\"\\nResults match: {torch.allclose(jac_fwd, jac_rev)}\")\n",
    "\n",
    "# Tall Jacobian example: R^3 -> R^10\n",
    "def h(x):\n",
    "    \"\"\"Function R^3 -> R^10 (tall Jacobian)\"\"\"\n",
    "    # Each output depends on inputs in different ways\n",
    "    return torch.cat([x, x**2, x**3, x.sum().unsqueeze(0)])\n",
    "\n",
    "x_tall = torch.randn(3)\n",
    "\n",
    "# jacrev is better here (fewer inputs)\n",
    "jac_tall_rev = jacrev(h)(x_tall)\n",
    "print(f\"\\njacrev for tall Jacobian: {jac_tall_rev.shape}  # (10, 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5c1d3",
   "metadata": {},
   "source": [
    "### Computing Hessians\n",
    "\n",
    "Combine `jacrev` with `grad` to compute Hessian matrices (second derivatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import grad\n",
    "\n",
    "# Scalar function for Hessian computation\n",
    "def scalar_func(x):\n",
    "    \"\"\"f(x) = x1^4 + x2^3 + x1*x2\"\"\"\n",
    "    return x[0]**4 + x[1]**3 + x[0]*x[1]\n",
    "\n",
    "x_hess = torch.tensor([1.0, 2.0])\n",
    "\n",
    "# Hessian = Jacobian of gradient\n",
    "# Method 1: jacrev(grad(f))\n",
    "hessian = jacrev(grad(scalar_func))(x_hess)\n",
    "print(f\"Hessian:\\n{hessian}\")\n",
    "print(f\"Shape: {hessian.shape}\")\n",
    "\n",
    "# Verify: Hessian should be symmetric for scalar functions\n",
    "print(f\"\\nHessian is symmetric: {torch.allclose(hessian, hessian.T)}\")\n",
    "\n",
    "# Manual computation for verification:\n",
    "# f = x1^4 + x2^3 + x1*x2\n",
    "# df/dx1 = 4*x1^3 + x2\n",
    "# df/dx2 = 3*x2^2 + x1\n",
    "# d²f/dx1² = 12*x1^2 = 12*1 = 12\n",
    "# d²f/dx2² = 6*x2 = 6*2 = 12\n",
    "# d²f/dx1dx2 = 1\n",
    "print(f\"\\nExpected diagonal: [12, 12]\")\n",
    "print(f\"Computed diagonal: {torch.diag(hessian)}\")\n",
    "print(f\"\\nExpected off-diagonal: 1\")\n",
    "print(f\"Computed off-diagonal: {hessian[0, 1].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2dc68",
   "metadata": {},
   "source": [
    "## Composing vmap and jacrev\n",
    "\n",
    "The real power comes from composing these transformations. Example: computing per-sample Jacobians in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Per-sample gradients in a neural network\n",
    "# This is useful for per-example gradient clipping, differential privacy, etc.\n",
    "\n",
    "def simple_model(params, x):\n",
    "    \"\"\"Simple linear model: y = W @ x + b\"\"\"\n",
    "    W, b = params\n",
    "    return W @ x + b\n",
    "\n",
    "# Model parameters\n",
    "W = torch.randn(3, 5)\n",
    "b = torch.randn(3)\n",
    "params = (W, b)\n",
    "\n",
    "# Batch of inputs\n",
    "batch_x = torch.randn(10, 5)  # 10 samples, 5 features each\n",
    "\n",
    "# Compute Jacobian w.r.t. input for each sample in batch\n",
    "# vmap over samples, jacrev over input dimensions\n",
    "per_sample_jacobians = vmap(lambda x: jacrev(lambda inp: simple_model(params, inp))(x))(batch_x)\n",
    "print(f\"Per-sample Jacobians shape: {per_sample_jacobians.shape}\")\n",
    "print(f\"(batch_size, output_dim, input_dim): ({per_sample_jacobians.shape})\")\n",
    "\n",
    "# Each element [i] is the Jacobian for sample i\n",
    "print(f\"\\nFirst sample Jacobian:\\n{per_sample_jacobians[0]}\")\n",
    "\n",
    "# Use case: Compute per-sample parameter gradients\n",
    "def loss_fn(params, x, y):\n",
    "    \"\"\"MSE loss for single example\"\"\"\n",
    "    pred = simple_model(params, x)\n",
    "    return ((pred - y) ** 2).sum()\n",
    "\n",
    "# Target outputs\n",
    "batch_y = torch.randn(10, 3)\n",
    "\n",
    "# Compute gradient w.r.t. params for each sample\n",
    "def compute_grad(x, y):\n",
    "    return grad(lambda p: loss_fn(p, x, y))(params)\n",
    "\n",
    "# vmap over the batch\n",
    "per_sample_grads = vmap(compute_grad)(batch_x, batch_y)\n",
    "print(f\"\\nPer-sample gradient shapes:\")\n",
    "print(f\"  W gradients: {per_sample_grads[0].shape}\")  # (10, 3, 5)\n",
    "print(f\"  b gradients: {per_sample_grads[1].shape}\")  # (10, 3)\n",
    "\n",
    "# Average gradient (equivalent to standard batch gradient)\n",
    "avg_grad_W = per_sample_grads[0].mean(dim=0)\n",
    "avg_grad_b = per_sample_grads[1].mean(dim=0)\n",
    "print(f\"\\nAverage gradient shapes:\")\n",
    "print(f\"  W: {avg_grad_W.shape}\")\n",
    "print(f\"  b: {avg_grad_b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ee298",
   "metadata": {},
   "source": [
    "## PDE Applications: Computing Spatial Derivatives\n",
    "\n",
    "For PDE solvers, we often need spatial derivatives. `jacrev` and `vmap` make this efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Computing Laplacian for physics-informed neural networks\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    \"\"\"Physics-Informed Neural Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"x: (batch, 2) -> u: (batch, 1)\"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "pinn = PINN()\n",
    "\n",
    "# Define function to compute Laplacian: ∇²u = ∂²u/∂x² + ∂²u/∂y²\n",
    "def compute_laplacian(model, point):\n",
    "    \"\"\"\n",
    "    Compute Laplacian of model output at a single point.\n",
    "    point: (2,) tensor [x, y]\n",
    "    \"\"\"\n",
    "    # First derivatives\n",
    "    def grad_u(p):\n",
    "        return grad(lambda x: model(x.unsqueeze(0)).squeeze())(p)\n",
    "    \n",
    "    # Jacobian of gradient = Hessian\n",
    "    hessian = jacrev(grad_u)(point)\n",
    "    \n",
    "    # Laplacian is trace of Hessian\n",
    "    laplacian = hessian.trace()\n",
    "    return laplacian\n",
    "\n",
    "# Test point\n",
    "test_point = torch.tensor([0.5, 0.5])\n",
    "laplacian_value = compute_laplacian(pinn, test_point)\n",
    "print(f\"Laplacian at {test_point.tolist()}: {laplacian_value.item():.4f}\")\n",
    "\n",
    "# Vectorize over batch of points using vmap\n",
    "points_batch = torch.rand(100, 2)  # 100 random points in [0,1]²\n",
    "\n",
    "# Compute Laplacian for all points efficiently\n",
    "laplacians_batch = vmap(lambda p: compute_laplacian(pinn, p))(points_batch)\n",
    "print(f\"\\nBatch Laplacians shape: {laplacians_batch.shape}\")\n",
    "print(f\"Mean Laplacian: {laplacians_batch.mean().item():.4f}\")\n",
    "print(f\"Std Laplacian: {laplacians_batch.std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af4553",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "**vmap:**\n",
    "- Doesn't allocate separate memory for each iteration - uses view/slice tricks\n",
    "- Can sometimes be slower than manual batching for simple operations\n",
    "- Shines when combining with other transforms or complex functions\n",
    "\n",
    "**jacrev/jacfwd:**\n",
    "- Choose based on Jacobian shape (tall vs wide)\n",
    "- For Hessians: `jacfwd(jacrev(f))` often faster than `jacrev(jacrev(f))`\n",
    "- Can combine with `vmap` for batched Jacobians\n",
    "\n",
    "**Memory considerations:**\n",
    "- Jacobians can be large: (m × n) for f: R^n → R^m\n",
    "- For PINNs, computing Laplacian is cheaper than full Hessian (only need trace)\n",
    "- Use `torch.no_grad()` when possible to save memory"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

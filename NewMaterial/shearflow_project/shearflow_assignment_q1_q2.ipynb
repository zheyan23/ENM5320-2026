{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19695757",
   "metadata": {},
   "source": [
    "# ENM5320 Shearflow Assignment (Q1 + Q2)\n",
    "\n",
    "This notebook addresses:\n",
    "1. **Q1**: Load and verify the **mean concentration field only**.\n",
    "2. **Q2**: Fit a **linear 3-point finite-difference stencil** to the mean concentration data.\n",
    "\n",
    "The notebook intentionally uses only `tracer_mean` as requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e7562",
   "metadata": {},
   "source": [
    "## Training Strategy (Required Explanation for Q2)\n",
    "\n",
    "We model the mean concentration profile $u(t,x)$ with a constant linear 3-point stencil\n",
    "$$L[u]_i = a u_{i-1} + b u_i + c u_{i+1},$$\n",
    "and use implicit Euler time stepping\n",
    "$$u^{n+1} = u^n + \\Delta t\\,L[u^{n+1}],$$\n",
    "which yields\n",
    "$$(I - \\Delta t\\,D(a,b,c))u^{n+1} = u^n.$$\n",
    "\n",
    "We optimize $(a,b,c)$ by rolling out this dynamics through all time steps and minimizing MSE to the observed mean concentration snapshots:\n",
    "$$\\mathcal{L} = \\frac{1}{NT}\\sum_{n,i}\\left(u^{n}_{\\text{pred},i} - u^{n}_{\\text{true},i}\\right)^2.$$\n",
    "\n",
    "Optimization uses Adam. This is a baseline model and does **not** include velocity coupling or unresolved nonlinear effects, as discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb424067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# MODIFY THESE PARAMETERS\n",
    "# ========================\n",
    "Re = 5e5\n",
    "Sc = 2.0e-1\n",
    "ic_index = 0\n",
    "\n",
    "print(f'Target case: Re={Re:.0e}, Sc={Sc:.1e}, ic={ic_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6474c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Load ONLY mean concentration field\n",
    "filename = f'shearflow_1d_profiles_Re{Re:.0e}_Sc{Sc:.1e}_ic{ic_index}.npz'\n",
    "path = Path(filename)\n",
    "\n",
    "if not path.exists():\n",
    "    url = 'https://raw.githubusercontent.com/natrask/ENM5320-2026/main/NewMaterial/shearflow_project/' + filename\n",
    "    print(f'Local file not found. Downloading from: {url}')\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    print('Download complete.')\n",
    "\n",
    "data = np.load(filename)\n",
    "\n",
    "# Load required arrays\n",
    "time = data['time']\n",
    "x = data['x']\n",
    "tracer_mean = data['tracer_mean']   # ONLY mean concentration field\n",
    "\n",
    "print('Loaded keys:', list(data.keys()))\n",
    "print('tracer_mean shape:', tracer_mean.shape)\n",
    "print('time range:', float(time[0]), '->', float(time[-1]))\n",
    "print('x range:', float(x[0]), '->', float(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 evidence plot 1: snapshots of mean concentration\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "n_time = len(time)\n",
    "idxs = [0, n_time//4, n_time//2, 3*n_time//4, n_time-1]\n",
    "for idx in idxs:\n",
    "    ax.plot(x, tracer_mean[idx], label=f't={time[idx]:.2f}')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('mean concentration')\n",
    "ax.set_title('Q1 Evidence: Mean concentration snapshots')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 evidence plot 2 and 3: spacetime map + variance decay\n",
    "variance_t = np.var(tracer_mean, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "im = axes[0].contourf(x, time, tracer_mean, levels=30, cmap='viridis')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('t')\n",
    "axes[0].set_title('Q1 Evidence: Mean concentration $c(t,x)$')\n",
    "plt.colorbar(im, ax=axes[0], label='c')\n",
    "\n",
    "axes[1].semilogy(time, variance_t, 'o-', ms=3)\n",
    "axes[1].set_xlabel('t')\n",
    "axes[1].set_ylabel('Var_x(c)')\n",
    "axes[1].set_title('Q1 Evidence: Spatial variance decay')\n",
    "axes[1].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00778571",
   "metadata": {},
   "source": [
    "## Q2: Fit a Linear 3-Point Stencil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "u_true = torch.tensor(tracer_mean, dtype=torch.float32, device=device)  # shape (T, N)\n",
    "t_torch = torch.tensor(time, dtype=torch.float32, device=device)\n",
    "x_torch = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "\n",
    "T, N = u_true.shape\n",
    "dt = float(time[1] - time[0])\n",
    "dx = float(x[1] - x[0])\n",
    "\n",
    "print(f'T={T}, N={N}, dt={dt:.4e}, dx={dx:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stencil_matrix_periodic(N, coeffs, device='cpu'):\n",
    "    # coeffs = [a, b, c]\n",
    "    a, b, c = coeffs[0], coeffs[1], coeffs[2]\n",
    "    D = torch.zeros((N, N), dtype=coeffs.dtype, device=device)\n",
    "    idx = torch.arange(N, device=device)\n",
    "    D[idx, idx] = b\n",
    "    D[idx, (idx - 1) % N] = a\n",
    "    D[idx, (idx + 1) % N] = c\n",
    "    return D\n",
    "\n",
    "def rollout_implicit_euler(u0, coeffs, T, dt):\n",
    "    N = u0.shape[0]\n",
    "    D = build_stencil_matrix_periodic(N, coeffs, device=u0.device)\n",
    "    A = torch.eye(N, device=u0.device, dtype=u0.dtype) - dt * D\n",
    "\n",
    "    u_hist = [u0]\n",
    "    u = u0\n",
    "    for _ in range(T - 1):\n",
    "        u = torch.linalg.solve(A, u)\n",
    "        u_hist.append(u)\n",
    "    return torch.stack(u_hist, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize near centered second-derivative stencil\n",
    "coeffs = torch.nn.Parameter(torch.tensor([1.0, -2.0, 1.0], device=device) / (dx**2))\n",
    "optimizer = torch.optim.Adam([coeffs], lr=5e-3)\n",
    "\n",
    "num_epochs = 2000\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    u_pred = rollout_implicit_euler(u_true[0], coeffs, T=T, dt=dt)\n",
    "    loss = torch.mean((u_pred - u_true) ** 2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_history.append(float(loss.item()))\n",
    "\n",
    "    if epoch % 200 == 0 or epoch == num_epochs - 1:\n",
    "        c = coeffs.detach().cpu().numpy()\n",
    "        print(f'Epoch {epoch:4d} | loss={loss.item():.4e} | coeffs={c}')\n",
    "\n",
    "print('Training complete.')\n",
    "print('Learned coeffs [a,b,c] =', coeffs.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 results: loss curve + prediction comparison\n",
    "with torch.no_grad():\n",
    "    u_fit = rollout_implicit_euler(u_true[0], coeffs, T=T, dt=dt).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "axes[0].semilogy(loss_history)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE loss')\n",
    "axes[0].set_title('Q2 Training loss')\n",
    "axes[0].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "idxs = [0, n_time//4, n_time//2, 3*n_time//4, n_time-1]\n",
    "for idx in idxs:\n",
    "    axes[1].plot(x, tracer_mean[idx], '-', lw=2, alpha=0.8)\n",
    "    axes[1].plot(x, u_fit[idx], '--', lw=1.5, alpha=0.8)\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('concentration')\n",
    "axes[1].set_title('Q2 True (solid) vs Linear-stencil fit (dashed)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report final errors\n",
    "with torch.no_grad():\n",
    "    u_fit_torch = rollout_implicit_euler(u_true[0], coeffs, T=T, dt=dt)\n",
    "    mse = torch.mean((u_fit_torch - u_true) ** 2).item()\n",
    "    rel_l2 = (torch.norm(u_fit_torch - u_true) / torch.norm(u_true)).item()\n",
    "\n",
    "print(f'Final MSE: {mse:.6e}')\n",
    "print(f'Relative L2 error: {rel_l2:.6e}')\n",
    "print('Learned stencil [a,b,c]:', coeffs.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351132f2",
   "metadata": {},
   "source": [
    "## Brief Discussion\n",
    "\n",
    "This linear stencil baseline captures part of the mean-concentration evolution but cannot represent full nonlinear transport physics.\n",
    "As noted in the assignment, the true process depends on velocity coupling and unresolved variability (e.g., standard deviations), which motivates nonlinear models in the next assignment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
